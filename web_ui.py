#!/usr/bin/env python
"""
Edge SLM Agent - Web UI
=======================
A beautiful web interface for Edge SLM Agent.

Run: python web_ui.py
"""

import sys
from pathlib import Path

# Add src to path
src_path = Path(__file__).parent / "src"
sys.path.insert(0, str(src_path))

import json
import gradio as gr
from typing import Optional
import asyncio

# Import project modules
from edge_slm.data.schema import LIGHT_ON_TOOLS, ToolCategory
from edge_slm.inference.structured import StructuredDecoder
from edge_slm.agent.router import AgentRouter, RoutingConfig, RoutingStrategy


# ============================================================================
# Global State
# ============================================================================
class AppState:
    """Application state manager."""
    def __init__(self):
        self.model_loaded = False
        self.model_path = None
        self.engine = None
        self.decoder = StructuredDecoder(use_outlines=False)
        self.router = AgentRouter(RoutingConfig(strategy=RoutingStrategy.SMART))
        
    def get_tools_info(self):
        """Get formatted tools information."""
        tools_by_category = {}
        for tool in LIGHT_ON_TOOLS:
            cat = tool.category.value
            if cat not in tools_by_category:
                tools_by_category[cat] = []
            tools_by_category[cat].append(tool)
        return tools_by_category


app_state = AppState()


# ============================================================================
# UI Functions
# ============================================================================

def get_tools_display():
    """Generate tools display HTML."""
    tools_by_category = app_state.get_tools_info()
    
    html = "<div style='max-height: 400px; overflow-y: auto;'>"
    
    category_icons = {
        "video_processing": "ğŸ¬",
        "subtitle_generation": "ğŸ“",
        "audio_dubbing": "ğŸ™ï¸",
        "file_management": "ğŸ“",
        "translation": "ğŸŒ",
        "content_analysis": "ğŸ“Š",
        "scheduling": "â°",
        "general": "âš™ï¸",
    }
    
    for category, tools in tools_by_category.items():
        icon = category_icons.get(category, "ğŸ“¦")
        html += f"<h4>{icon} {category.replace('_', ' ').title()}</h4>"
        html += "<ul>"
        for tool in tools:
            params = ", ".join([p.name for p in tool.parameters[:3]])
            if len(tool.parameters) > 3:
                params += "..."
            html += f"<li><b>{tool.name}</b>({params})<br/>"
            html += f"<small style='color: #666;'>{tool.description[:80]}...</small></li>"
        html += "</ul>"
    
    html += "</div>"
    return html


def run_inference(query: str, use_structured: bool = True) -> tuple:
    """Run inference on user query."""
    if not query.strip():
        return "è¯·è¾“å…¥æŸ¥è¯¢å†…å®¹", "", ""
    
    # Get routing decision
    tools = [t.to_openai_format() for t in LIGHT_ON_TOOLS]
    decision = app_state.router.should_use_local(query, tools)
    
    routing_info = f"""**è·¯ç”±å†³ç­–:**
- ä½¿ç”¨æœ¬åœ°æ¨¡å‹: {'âœ… æ˜¯' if decision.use_local else 'âŒ å¦ (å»ºè®®ä½¿ç”¨äº‘ç«¯)'}
- å¤æ‚åº¦è¯„ä¼°: {decision.estimated_complexity.value}
- ç½®ä¿¡åº¦: {decision.confidence:.2f}
- åŸå› : {decision.reason}
"""
    
    # Simulate model output (since model might not be loaded)
    # In real scenario, this would call the actual model
    simulated_output = simulate_tool_call(query)
    
    # Parse the output
    parsed = app_state.decoder._extract_json(simulated_output)
    
    if isinstance(parsed, dict):
        formatted_result = json.dumps(parsed, indent=2, ensure_ascii=False)
        status = "âœ… è§£ææˆåŠŸ"
    else:
        formatted_result = str(parsed)
        status = "âš ï¸ è§£æç»“æœ"
    
    return status, formatted_result, routing_info


def simulate_tool_call(query: str) -> str:
    """Simulate a tool call based on query keywords."""
    query_lower = query.lower()
    
    if "è§†é¢‘" in query or "video" in query_lower:
        if "å­—å¹•" in query or "subtitle" in query_lower:
            return json.dumps({
                "name": "generate_subtitles",
                "arguments": {
                    "video_url": extract_url(query) or "https://example.com/video.mp4",
                    "source_language": "zh",
                    "output_format": "srt"
                }
            }, ensure_ascii=False)
        elif "åˆ†æ" in query or "analyze" in query_lower:
            return json.dumps({
                "name": "analyze_content",
                "arguments": {
                    "video_url": extract_url(query) or "https://example.com/video.mp4",
                    "analysis_type": "all",
                    "detail_level": "detailed"
                }
            }, ensure_ascii=False)
        else:
            return json.dumps({
                "name": "parse_video",
                "arguments": {
                    "video_url": extract_url(query) or "https://example.com/video.mp4",
                    "extract_frames": False
                }
            }, ensure_ascii=False)
    
    elif "ç¿»è¯‘" in query or "translate" in query_lower:
        return json.dumps({
            "name": "translate_subtitles",
            "arguments": {
                "subtitle_file": "subtitles.srt",
                "source_language": "zh",
                "target_language": "en"
            }
        }, ensure_ascii=False)
    
    elif "é…éŸ³" in query or "dubbing" in query_lower:
        return json.dumps({
            "name": "generate_dubbing",
            "arguments": {
                "video_url": extract_url(query) or "https://example.com/video.mp4",
                "subtitle_file": "subtitles.srt",
                "voice_id": "voice_001",
                "target_language": "en"
            }
        }, ensure_ascii=False)
    
    elif "å¯¼å‡º" in query or "export" in query_lower:
        return json.dumps({
            "name": "export_project",
            "arguments": {
                "project_id": "proj_001",
                "output_format": "mp4",
                "quality": "1080p"
            }
        }, ensure_ascii=False)
    
    else:
        return json.dumps({
            "name": "parse_video",
            "arguments": {
                "video_url": "https://example.com/video.mp4"
            }
        }, ensure_ascii=False)


def extract_url(text: str) -> Optional[str]:
    """Extract URL from text."""
    import re
    url_pattern = r'https?://[^\s<>"{}|\\^`\[\]]+'
    match = re.search(url_pattern, text)
    return match.group(0) if match else None


def test_json_extraction(raw_output: str) -> tuple:
    """Test JSON extraction from raw model output."""
    if not raw_output.strip():
        return "è¯·è¾“å…¥æ¨¡å‹è¾“å‡º", ""
    
    result = app_state.decoder._extract_json(raw_output)
    
    if isinstance(result, dict):
        return "âœ… æå–æˆåŠŸ", json.dumps(result, indent=2, ensure_ascii=False)
    else:
        return "âŒ æå–å¤±è´¥", str(result)


def generate_sample_data(num_samples: int, categories: list) -> str:
    """Generate sample training data preview."""
    from edge_slm.data.schema import ToolUseExample, ToolCall
    
    samples = []
    
    # Sample queries for each category
    sample_queries = {
        "video_processing": [
            ("å¸®æˆ‘è§£æè¿™ä¸ªè§†é¢‘ https://example.com/v.mp4", "parse_video", {"video_url": "https://example.com/v.mp4"}),
        ],
        "subtitle_generation": [
            ("ä¸ºè§†é¢‘ç”Ÿæˆä¸­æ–‡å­—å¹•", "generate_subtitles", {"video_url": "video.mp4", "source_language": "zh"}),
        ],
        "translation": [
            ("æŠŠå­—å¹•ç¿»è¯‘æˆè‹±æ–‡", "translate_subtitles", {"subtitle_file": "sub.srt", "source_language": "zh", "target_language": "en"}),
        ],
        "audio_dubbing": [
            ("ç»™è§†é¢‘é…éŸ³", "generate_dubbing", {"video_url": "v.mp4", "subtitle_file": "s.srt", "voice_id": "v1", "target_language": "en"}),
        ],
        "content_analysis": [
            ("åˆ†æè§†é¢‘å†…å®¹", "analyze_content", {"video_url": "v.mp4", "analysis_type": "all"}),
        ],
    }
    
    count = 0
    for cat in categories:
        if cat in sample_queries and count < num_samples:
            for query, tool_name, args in sample_queries[cat]:
                if count >= num_samples:
                    break
                    
                tool = next((t for t in LIGHT_ON_TOOLS if t.name == tool_name), None)
                if tool:
                    example = ToolUseExample(
                        user_query=query,
                        available_tools=[tool],
                        tool_calls=[ToolCall(name=tool_name, arguments=args)],
                        category=tool.category,
                    )
                    samples.append(example.to_training_format())
                    count += 1
    
    if not samples:
        return "è¯·é€‰æ‹©è‡³å°‘ä¸€ä¸ªç±»åˆ«"
    
    return json.dumps(samples[:3], indent=2, ensure_ascii=False) + f"\n\n... å…± {len(samples)} æ¡æ ·æœ¬"


def get_model_status() -> str:
    """Get current model status."""
    if app_state.model_loaded:
        return f"âœ… æ¨¡å‹å·²åŠ è½½: {app_state.model_path}"
    return "âš ï¸ æ¨¡å‹æœªåŠ è½½ (ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼)"


# ============================================================================
# Build UI
# ============================================================================

def create_ui():
    """Create the Gradio interface."""
    
    # Custom CSS
    custom_css = """
    .gradio-container {
        max-width: 1200px !important;
    }
    .tool-card {
        border: 1px solid #e0e0e0;
        border-radius: 8px;
        padding: 12px;
        margin: 8px 0;
    }
    .status-box {
        padding: 10px;
        border-radius: 6px;
        margin: 10px 0;
    }
    .success { background-color: #d4edda; }
    .warning { background-color: #fff3cd; }
    .error { background-color: #f8d7da; }
    """
    
    with gr.Blocks(
        title="Edge SLM Agent",
        theme=gr.themes.Soft(
            primary_hue="blue",
            secondary_hue="gray",
        ),
        css=custom_css
    ) as demo:
        
        # Header
        gr.Markdown("""
        # ğŸš€ Edge SLM Agent
        ### ç«¯ä¾§è½»é‡åŒ–æ¨¡å‹å¾®è°ƒä¸ç»“æ„åŒ–æ¨ç†ä¼˜åŒ–
        
        ---
        """)
        
        # Status bar
        with gr.Row():
            status_display = gr.Markdown(get_model_status())
            refresh_btn = gr.Button("ğŸ”„ åˆ·æ–°çŠ¶æ€", size="sm")
            refresh_btn.click(fn=get_model_status, outputs=status_display)
        
        # Main tabs
        with gr.Tabs():
            
            # ================================================================
            # Tab 1: Inference
            # ================================================================
            with gr.TabItem("ğŸ’¬ æ¨ç†æµ‹è¯•", id="inference"):
                gr.Markdown("### æµ‹è¯•å·¥å…·è°ƒç”¨æ¨ç†")
                
                with gr.Row():
                    with gr.Column(scale=2):
                        query_input = gr.Textbox(
                            label="ç”¨æˆ·æŸ¥è¯¢",
                            placeholder="ä¾‹å¦‚: å¸®æˆ‘åˆ†æè§†é¢‘ https://example.com/video.mp4",
                            lines=3
                        )
                        
                        with gr.Row():
                            structured_check = gr.Checkbox(
                                label="ä½¿ç”¨ç»“æ„åŒ–è§£ç ",
                                value=True
                            )
                            infer_btn = gr.Button("ğŸš€ è¿è¡Œæ¨ç†", variant="primary")
                        
                        # Example queries
                        gr.Examples(
                            examples=[
                                ["å¸®æˆ‘è§£æè§†é¢‘ https://example.com/video.mp4"],
                                ["ä¸ºè¿™ä¸ªè§†é¢‘ç”Ÿæˆä¸­æ–‡å­—å¹•"],
                                ["æŠŠå­—å¹•ç¿»è¯‘æˆè‹±æ–‡"],
                                ["åˆ†æè§†é¢‘å†…å®¹å¹¶æå–å…³é”®ä¿¡æ¯"],
                                ["ç»™è§†é¢‘é…ä¸Šè‹±æ–‡é…éŸ³"],
                            ],
                            inputs=query_input,
                            label="ç¤ºä¾‹æŸ¥è¯¢"
                        )
                    
                    with gr.Column(scale=2):
                        infer_status = gr.Markdown("ç­‰å¾…è¾“å…¥...")
                        result_output = gr.Code(
                            label="å·¥å…·è°ƒç”¨ç»“æœ",
                            language="json",
                            lines=10
                        )
                        routing_output = gr.Markdown(label="è·¯ç”±ä¿¡æ¯")
                
                infer_btn.click(
                    fn=run_inference,
                    inputs=[query_input, structured_check],
                    outputs=[infer_status, result_output, routing_output]
                )
            
            # ================================================================
            # Tab 2: Tools Browser
            # ================================================================
            with gr.TabItem("ğŸ› ï¸ å·¥å…·æµè§ˆ", id="tools"):
                gr.Markdown("### å¯ç”¨å·¥å…·åˆ—è¡¨")
                
                tools_html = gr.HTML(get_tools_display())
                
                gr.Markdown("---")
                gr.Markdown("### å·¥å…· Schema é¢„è§ˆ")
                
                tool_selector = gr.Dropdown(
                    choices=[t.name for t in LIGHT_ON_TOOLS],
                    label="é€‰æ‹©å·¥å…·",
                    value=LIGHT_ON_TOOLS[0].name
                )
                
                schema_output = gr.Code(
                    label="JSON Schema",
                    language="json",
                    lines=15
                )
                
                def show_tool_schema(tool_name):
                    tool = next((t for t in LIGHT_ON_TOOLS if t.name == tool_name), None)
                    if tool:
                        return json.dumps(tool.to_openai_format(), indent=2, ensure_ascii=False)
                    return "{}"
                
                tool_selector.change(
                    fn=show_tool_schema,
                    inputs=tool_selector,
                    outputs=schema_output
                )
                
                # Initialize with first tool
                demo.load(
                    fn=lambda: show_tool_schema(LIGHT_ON_TOOLS[0].name),
                    outputs=schema_output
                )
            
            # ================================================================
            # Tab 3: JSON Extraction Test
            # ================================================================
            with gr.TabItem("ğŸ” JSON æå–æµ‹è¯•", id="extraction"):
                gr.Markdown("""
                ### æµ‹è¯• JSON æå–åŠŸèƒ½
                
                æ¨¡æ‹Ÿä»æ¨¡å‹è¾“å‡ºä¸­æå–æœ‰æ•ˆ JSONï¼Œæ”¯æŒå¤„ç†å„ç§æ ¼å¼é—®é¢˜ã€‚
                """)
                
                with gr.Row():
                    with gr.Column():
                        raw_input = gr.Textbox(
                            label="æ¨¡å‹åŸå§‹è¾“å‡º",
                            placeholder='ä¾‹å¦‚: Let me help you. {"name": "parse_video", "arguments": {...}}',
                            lines=5
                        )
                        extract_btn = gr.Button("ğŸ” æå– JSON", variant="primary")
                        
                        gr.Examples(
                            examples=[
                                ['{"name": "parse_video", "arguments": {"video_url": "https://example.com/v.mp4"}}'],
                                ["Let me help you. {'name': 'parse_video', 'arguments': {'video_url': 'test.mp4'}}"],
                                ['The tool to use is: {"name": "generate_subtitles", "arguments": {"video_url": "v.mp4", "source_language": "zh",}}'],
                                ['```json\n{"name": "analyze_content", "arguments": {"video_url": "v.mp4"}}\n```'],
                            ],
                            inputs=raw_input,
                            label="æµ‹è¯•ç”¨ä¾‹"
                        )
                    
                    with gr.Column():
                        extract_status = gr.Markdown("ç­‰å¾…è¾“å…¥...")
                        extracted_output = gr.Code(
                            label="æå–ç»“æœ",
                            language="json",
                            lines=8
                        )
                
                extract_btn.click(
                    fn=test_json_extraction,
                    inputs=raw_input,
                    outputs=[extract_status, extracted_output]
                )
            
            # ================================================================
            # Tab 4: Data Generation
            # ================================================================
            with gr.TabItem("ğŸ“Š æ•°æ®ç”Ÿæˆ", id="datagen"):
                gr.Markdown("""
                ### è®­ç»ƒæ•°æ®ç”Ÿæˆ
                
                ç”Ÿæˆç”¨äºå¾®è°ƒçš„è®­ç»ƒæ•°æ®æ ·æœ¬é¢„è§ˆã€‚
                """)
                
                with gr.Row():
                    with gr.Column():
                        num_samples_slider = gr.Slider(
                            minimum=1,
                            maximum=100,
                            value=10,
                            step=1,
                            label="æ ·æœ¬æ•°é‡"
                        )
                        
                        category_select = gr.CheckboxGroup(
                            choices=[
                                "video_processing",
                                "subtitle_generation", 
                                "translation",
                                "audio_dubbing",
                                "content_analysis"
                            ],
                            value=["video_processing", "subtitle_generation"],
                            label="é€‰æ‹©ç±»åˆ«"
                        )
                        
                        gen_btn = gr.Button("ğŸ“ ç”Ÿæˆæ ·æœ¬é¢„è§ˆ", variant="primary")
                    
                    with gr.Column():
                        sample_output = gr.Code(
                            label="æ ·æœ¬é¢„è§ˆ",
                            language="json",
                            lines=20
                        )
                
                gen_btn.click(
                    fn=generate_sample_data,
                    inputs=[num_samples_slider, category_select],
                    outputs=sample_output
                )
            
            # ================================================================
            # Tab 5: Settings & Help
            # ================================================================
            with gr.TabItem("âš™ï¸ è®¾ç½®ä¸å¸®åŠ©", id="settings"):
                gr.Markdown("""
                ### ä½¿ç”¨è¯´æ˜
                
                #### å‘½ä»¤è¡Œå·¥å…·
                
                ```bash
                # ç”Ÿæˆè®­ç»ƒæ•°æ®
                python run.py distill --num-samples 100
                
                # è®­ç»ƒæ¨¡å‹
                python run.py train data/sample_train.jsonl
                
                # å¯åŠ¨æ¨ç†æœåŠ¡
                python run.py serve outputs/model --port 8000
                
                # è¿è¡Œæ¨ç†
                python run.py infer outputs/model "å¸®æˆ‘åˆ†æè§†é¢‘"
                
                # åŸºå‡†æµ‹è¯•
                python run.py benchmark outputs/model
                ```
                
                #### é¡¹ç›®ç‰¹æ€§
                
                - **ç»“æ„åŒ–è§£ç **: ä½¿ç”¨ Grammar-Constrained Decoding ç¡®ä¿ 100% æœ‰æ•ˆ JSON è¾“å‡º
                - **æ™ºèƒ½è·¯ç”±**: è‡ªåŠ¨åˆ¤æ–­ä½¿ç”¨æœ¬åœ°æ¨¡å‹æˆ–äº‘ç«¯ API
                - **è½»é‡åŒ–å¾®è°ƒ**: æ”¯æŒ LoRA/QLoRA é«˜æ•ˆå¾®è°ƒ
                - **å¤šå·¥å…·æ”¯æŒ**: 8 ç§è§†é¢‘å¤„ç†ç›¸å…³å·¥å…·
                
                #### ç³»ç»Ÿè¦æ±‚
                
                - Python 3.10+
                - PyTorch 2.1+
                - (å¯é€‰) CUDA 11.8+ ç”¨äº GPU åŠ é€Ÿ
                - (å¯é€‰) Rust ç”¨äº Outlines ç»“æ„åŒ–è§£ç 
                
                ---
                
                ### å…³äº
                
                Edge SLM Agent æ˜¯ä¸€ä¸ªç«¯ä¾§è½»é‡åŒ–æ¨¡å‹å¾®è°ƒä¸ç»“æ„åŒ–æ¨ç†ä¼˜åŒ–é¡¹ç›®ï¼Œ
                ä¸“æ³¨äºåœ¨èµ„æºå—é™çš„ç¯å¢ƒä¸‹å®ç°é«˜æ•ˆçš„å·¥å…·è°ƒç”¨èƒ½åŠ›ã€‚
                """)
        
        # Footer
        gr.Markdown("""
        ---
        <center>
        <small>Edge SLM Agent v1.0 | Built with Gradio</small>
        </center>
        """)
    
    return demo


# ============================================================================
# Main
# ============================================================================

if __name__ == "__main__":
    print("ğŸš€ Starting Edge SLM Agent Web UI...")
    print("=" * 50)
    
    demo = create_ui()
    demo.launch(
        server_name="127.0.0.1",
        server_port=7860,
        share=False,
        show_error=True,
    )
