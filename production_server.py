"""
ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²ç¤ºä¾‹ - Edge SLM Agent API æœåŠ¡

ä½¿ç”¨æ–¹æ³•:
1. è®­ç»ƒæ¨¡å‹: python run.py train data/distilled/tool_use_train.jsonl --output-dir outputs/model
2. å¯åŠ¨æœåŠ¡: python production_server.py
3. è°ƒç”¨ API: curl -X POST http://localhost:8000/api/process -d '{"query": "åˆ†æè§†é¢‘ xxx.mp4"}'
"""

import sys
sys.path.insert(0, "src")

import json
import asyncio
from typing import Optional, Dict, Any
from pathlib import Path
from datetime import datetime

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import uvicorn


# ==================== é…ç½® ====================

MODEL_PATH = "outputs/model"  # è®­ç»ƒå¥½çš„æ¨¡å‹è·¯å¾„
USE_GPU = True
PORT = 8000


# ==================== æ•°æ®æ¨¡å‹ ====================

class ProcessRequest(BaseModel):
    """ç”¨æˆ·è¯·æ±‚"""
    query: str
    context: Optional[Dict[str, Any]] = None

class ProcessResponse(BaseModel):
    """å¤„ç†å“åº”"""
    success: bool
    tool_call: Optional[Dict[str, Any]] = None
    result: Optional[Any] = None
    error: Optional[str] = None
    latency_ms: float


# ==================== å·¥å…·æ‰§è¡Œå™¨ ====================

class ToolExecutor:
    """
    çœŸå®çš„å·¥å…·æ‰§è¡Œå™¨
    åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œè¿™é‡Œä¼šè°ƒç”¨çœŸå®çš„ API
    """
    
    async def execute(self, tool_name: str, arguments: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œå·¥å…·è°ƒç”¨"""
        
        # è¿™é‡Œæ˜¯æ¨¡æ‹Ÿå®ç°ï¼Œå®é™…åº”ç”¨ä¸­æ›¿æ¢ä¸ºçœŸå® API è°ƒç”¨
        handlers = {
            "parse_video": self._parse_video,
            "generate_subtitles": self._generate_subtitles,
            "translate_subtitles": self._translate_subtitles,
            "generate_dubbing": self._generate_dubbing,
            "analyze_content": self._analyze_content,
            "schedule_task": self._schedule_task,
            "export_project": self._export_project,
            "list_voices": self._list_voices,
        }
        
        handler = handlers.get(tool_name)
        if handler:
            return await handler(arguments)
        else:
            return {"error": f"Unknown tool: {tool_name}"}
    
    async def _parse_video(self, args: Dict) -> Dict:
        """è§£æè§†é¢‘ - å®é™…åº”ç”¨ä¸­è°ƒç”¨ FFmpeg æˆ–è§†é¢‘å¤„ç† API"""
        video_url = args.get("video_url", "")
        # æ¨¡æ‹Ÿè¿”å›
        return {
            "status": "success",
            "video_url": video_url,
            "duration": "00:05:30",
            "resolution": "1920x1080",
            "fps": 30,
            "codec": "h264",
            "size_mb": 125.5
        }
    
    async def _generate_subtitles(self, args: Dict) -> Dict:
        """ç”Ÿæˆå­—å¹• - å®é™…åº”ç”¨ä¸­è°ƒç”¨ Whisper æˆ–è¯­éŸ³è¯†åˆ« API"""
        return {
            "status": "success",
            "subtitle_file": "/output/subtitles.srt",
            "language": args.get("source_language", "auto"),
            "segments": 45
        }
    
    async def _translate_subtitles(self, args: Dict) -> Dict:
        """ç¿»è¯‘å­—å¹• - å®é™…åº”ç”¨ä¸­è°ƒç”¨ç¿»è¯‘ API"""
        return {
            "status": "success",
            "output_file": "/output/translated.srt",
            "source_language": args.get("source_language"),
            "target_language": args.get("target_language"),
            "segments_translated": 45
        }
    
    async def _generate_dubbing(self, args: Dict) -> Dict:
        """ç”Ÿæˆé…éŸ³ - å®é™…åº”ç”¨ä¸­è°ƒç”¨ TTS API"""
        return {
            "status": "success",
            "audio_file": "/output/dubbing.mp3",
            "voice_id": args.get("voice_id"),
            "duration": "00:05:30"
        }
    
    async def _analyze_content(self, args: Dict) -> Dict:
        """åˆ†æå†…å®¹ - å®é™…åº”ç”¨ä¸­è°ƒç”¨è§†é¢‘åˆ†æ API"""
        return {
            "status": "success",
            "topics": ["æŠ€æœ¯æ•™ç¨‹", "ç¼–ç¨‹"],
            "sentiment": "positive",
            "key_moments": [
                {"time": "00:01:30", "description": "ä»‹ç»éƒ¨åˆ†"},
                {"time": "00:03:00", "description": "æ ¸å¿ƒå†…å®¹"}
            ]
        }
    
    async def _schedule_task(self, args: Dict) -> Dict:
        """è°ƒåº¦ä»»åŠ¡ - å®é™…åº”ç”¨ä¸­å†™å…¥ä»»åŠ¡é˜Ÿåˆ—"""
        return {
            "status": "scheduled",
            "task_id": f"task_{datetime.now().strftime('%Y%m%d%H%M%S')}",
            "task_type": args.get("task_type"),
            "scheduled_time": args.get("scheduled_time")
        }
    
    async def _export_project(self, args: Dict) -> Dict:
        """å¯¼å‡ºé¡¹ç›® - å®é™…åº”ç”¨ä¸­è°ƒç”¨è§†é¢‘ç¼–ç å™¨"""
        return {
            "status": "success",
            "output_file": f"/output/{args.get('project_id')}.{args.get('output_format', 'mp4')}",
            "format": args.get("output_format", "mp4"),
            "quality": args.get("quality", "1080p")
        }
    
    async def _list_voices(self, args: Dict) -> Dict:
        """åˆ—å‡ºå¯ç”¨è¯­éŸ³"""
        voices = {
            "zh-CN": ["zh-CN-XiaoxiaoNeural", "zh-CN-YunxiNeural"],
            "en-US": ["en-US-JennyNeural", "en-US-GuyNeural"],
            "ja-JP": ["ja-JP-NanamiNeural", "ja-JP-KeitaNeural"],
        }
        lang = args.get("language", "zh-CN")
        return {
            "status": "success",
            "language": lang,
            "voices": voices.get(lang, voices["en-US"])
        }


# ==================== æ¨ç†å¼•æ“ ====================

class ProductionEngine:
    """ç”Ÿäº§ç¯å¢ƒæ¨ç†å¼•æ“"""
    
    def __init__(self, model_path: str):
        self.model_path = model_path
        self.model = None
        self.tokenizer = None
        self.tool_executor = ToolExecutor()
        self._loaded = False
    
    def load(self):
        """åŠ è½½æ¨¡å‹"""
        if self._loaded:
            return
        
        model_dir = Path(self.model_path)
        
        if not model_dir.exists():
            print(f"âš ï¸ æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {model_path}")
            print("ğŸ“ å°†ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼è¿è¡Œï¼ˆç”¨äºæ¼”ç¤ºï¼‰")
            self._loaded = True
            return
        
        try:
            from transformers import AutoModelForCausalLM, AutoTokenizer
            import torch
            
            print(f"ğŸ”„ åŠ è½½æ¨¡å‹: {self.model_path}")
            
            self.tokenizer = AutoTokenizer.from_pretrained(
                self.model_path,
                trust_remote_code=True
            )
            
            self.model = AutoModelForCausalLM.from_pretrained(
                self.model_path,
                torch_dtype=torch.float16 if USE_GPU else torch.float32,
                device_map="auto" if USE_GPU else "cpu",
                trust_remote_code=True
            )
            
            print("âœ… æ¨¡å‹åŠ è½½å®Œæˆ")
            self._loaded = True
            
        except Exception as e:
            print(f"âš ï¸ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            print("ğŸ“ å°†ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼è¿è¡Œ")
            self._loaded = True
    
    async def process(self, query: str) -> Dict[str, Any]:
        """å¤„ç†ç”¨æˆ·è¯·æ±‚"""
        import time
        start_time = time.time()
        
        # 1. æ„å›¾è¯†åˆ«ï¼ˆè°ƒç”¨æ¨¡å‹ï¼‰
        tool_call = await self._infer(query)
        
        # 2. æ‰§è¡Œå·¥å…·
        if tool_call and "name" in tool_call:
            result = await self.tool_executor.execute(
                tool_call["name"],
                tool_call.get("arguments", {})
            )
        else:
            result = None
        
        latency = (time.time() - start_time) * 1000
        
        return {
            "tool_call": tool_call,
            "result": result,
            "latency_ms": latency
        }
    
    async def _infer(self, query: str) -> Optional[Dict]:
        """æ¨¡å‹æ¨ç†"""
        
        if self.model is None:
            # æ¨¡æ‹Ÿæ¨¡å¼ï¼šç®€å•çš„å…³é”®è¯åŒ¹é…
            return self._mock_infer(query)
        
        # çœŸå®æ¨¡å‹æ¨ç†
        try:
            from edge_slm.data.schema import LIGHT_ON_TOOLS
            
            # æ„å»º prompt
            tools_desc = "\n".join([
                f"- {t['function']['name']}: {t['function']['description']}"
                for t in LIGHT_ON_TOOLS
            ])
            
            prompt = f"""You are an AI assistant that helps users by calling appropriate tools.
Available tools:
{tools_desc}

User: {query}
Assistant: """
            
            inputs = self.tokenizer(prompt, return_tensors="pt")
            if USE_GPU:
                inputs = {k: v.cuda() for k, v in inputs.items()}
            
            outputs = self.model.generate(
                **inputs,
                max_new_tokens=256,
                temperature=0.1,
                do_sample=True,
                pad_token_id=self.tokenizer.eos_token_id
            )
            
            response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
            response = response.split("Assistant:")[-1].strip()
            
            # æå– JSON
            import re
            json_match = re.search(r'\{[^{}]*\}', response)
            if json_match:
                return json.loads(json_match.group())
            
        except Exception as e:
            print(f"æ¨ç†é”™è¯¯: {e}")
        
        return None
    
    def _mock_infer(self, query: str) -> Dict:
        """æ¨¡æ‹Ÿæ¨ç†ï¼ˆç”¨äºæ¼”ç¤ºï¼‰"""
        query_lower = query.lower()
        
        if "åˆ†æ" in query or "parse" in query_lower or "è§£æ" in query:
            return {
                "name": "parse_video",
                "arguments": {"video_url": self._extract_url(query)}
            }
        elif "å­—å¹•" in query or "subtitle" in query_lower:
            if "ç¿»è¯‘" in query or "translate" in query_lower:
                return {
                    "name": "translate_subtitles",
                    "arguments": {
                        "subtitle_file": "/input/subtitle.srt",
                        "source_language": "zh",
                        "target_language": "en"
                    }
                }
            else:
                return {
                    "name": "generate_subtitles",
                    "arguments": {
                        "video_url": self._extract_url(query),
                        "source_language": "zh",
                        "output_format": "srt"
                    }
                }
        elif "é…éŸ³" in query or "dubbing" in query_lower or "è¯­éŸ³" in query:
            return {
                "name": "generate_dubbing",
                "arguments": {
                    "video_url": self._extract_url(query),
                    "subtitle_file": "/input/subtitle.srt",
                    "voice_id": "zh-CN-XiaoxiaoNeural",
                    "target_language": "zh"
                }
            }
        elif "å¯¼å‡º" in query or "export" in query_lower:
            return {
                "name": "export_project",
                "arguments": {
                    "project_id": "project_001",
                    "output_format": "mp4",
                    "quality": "1080p"
                }
            }
        elif "å®‰æ’" in query or "schedule" in query_lower:
            return {
                "name": "schedule_task",
                "arguments": {
                    "task_type": "parse",
                    "task_params": {"video_url": self._extract_url(query)},
                    "scheduled_time": "2024-12-25T10:00:00Z",
                    "priority": "normal"
                }
            }
        else:
            return {
                "name": "analyze_content",
                "arguments": {
                    "video_url": self._extract_url(query),
                    "analysis_type": "all"
                }
            }
    
    def _extract_url(self, text: str) -> str:
        """ä»æ–‡æœ¬ä¸­æå– URL"""
        import re
        url_match = re.search(r'https?://\S+|/\S+\.\w+', text)
        return url_match.group() if url_match else "https://example.com/video.mp4"


# ==================== FastAPI åº”ç”¨ ====================

app = FastAPI(
    title="Edge SLM Agent API",
    description="ç«¯ä¾§è½»é‡åŒ–æ¨¡å‹æ¨ç†æœåŠ¡",
    version="1.0.0"
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# å…¨å±€å¼•æ“å®ä¾‹
engine: Optional[ProductionEngine] = None


@app.on_event("startup")
async def startup():
    """å¯åŠ¨æ—¶åŠ è½½æ¨¡å‹"""
    global engine
    engine = ProductionEngine(MODEL_PATH)
    engine.load()


@app.get("/")
async def root():
    """å¥åº·æ£€æŸ¥"""
    return {
        "status": "ok",
        "service": "Edge SLM Agent",
        "model_loaded": engine._loaded if engine else False
    }


@app.post("/api/process", response_model=ProcessResponse)
async def process(request: ProcessRequest):
    """
    å¤„ç†ç”¨æˆ·è¯·æ±‚
    
    ç¤ºä¾‹:
    - "å¸®æˆ‘åˆ†æè§†é¢‘ https://example.com/video.mp4"
    - "ç»™è§†é¢‘æ·»åŠ ä¸­æ–‡å­—å¹•"
    - "æŠŠå­—å¹•ç¿»è¯‘æˆè‹±æ–‡"
    """
    if not engine:
        raise HTTPException(status_code=503, detail="Service not ready")
    
    try:
        result = await engine.process(request.query)
        return ProcessResponse(
            success=True,
            tool_call=result["tool_call"],
            result=result["result"],
            latency_ms=result["latency_ms"]
        )
    except Exception as e:
        return ProcessResponse(
            success=False,
            error=str(e),
            latency_ms=0
        )


@app.get("/api/tools")
async def list_tools():
    """åˆ—å‡ºæ‰€æœ‰å¯ç”¨å·¥å…·"""
    try:
        from edge_slm.data.schema import LIGHT_ON_TOOLS
        return {
            "tools": [
                {
                    "name": t["function"]["name"],
                    "description": t["function"]["description"]
                }
                for t in LIGHT_ON_TOOLS
            ]
        }
    except:
        return {
            "tools": [
                {"name": "parse_video", "description": "è§£æè§†é¢‘æ–‡ä»¶"},
                {"name": "generate_subtitles", "description": "ç”Ÿæˆå­—å¹•"},
                {"name": "translate_subtitles", "description": "ç¿»è¯‘å­—å¹•"},
                {"name": "generate_dubbing", "description": "ç”Ÿæˆé…éŸ³"},
                {"name": "analyze_content", "description": "åˆ†æå†…å®¹"},
                {"name": "schedule_task", "description": "è°ƒåº¦ä»»åŠ¡"},
                {"name": "export_project", "description": "å¯¼å‡ºé¡¹ç›®"},
                {"name": "list_voices", "description": "åˆ—å‡ºè¯­éŸ³"},
            ]
        }


# ==================== ä¸»å…¥å£ ====================

if __name__ == "__main__":
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘           Edge SLM Agent - ç”Ÿäº§ç¯å¢ƒ API æœåŠ¡                  â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  ç«¯ç‚¹:                                                        â•‘
â•‘  â€¢ GET  /           - å¥åº·æ£€æŸ¥                                â•‘
â•‘  â€¢ POST /api/process - å¤„ç†ç”¨æˆ·è¯·æ±‚                           â•‘
â•‘  â€¢ GET  /api/tools   - åˆ—å‡ºå¯ç”¨å·¥å…·                           â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  ç¤ºä¾‹è¯·æ±‚:                                                    â•‘
â•‘  curl -X POST http://localhost:8000/api/process \\            â•‘
â•‘       -H "Content-Type: application/json" \\                  â•‘
â•‘       -d '{"query": "åˆ†æè§†é¢‘ https://example.com/v.mp4"}'    â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    uvicorn.run(app, host="0.0.0.0", port=PORT)
